{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf1def7",
   "metadata": {},
   "source": [
    "# 2-Layer Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b4203",
   "metadata": {},
   "source": [
    "1. Size of layers and initializing parameters\n",
    "2. Forward propagation\n",
    "3. Loss function and cost function\n",
    "4. Backward propagation\n",
    "5. Update parameters\n",
    "6. Prediction with learning parameters weight and bias\n",
    "7. Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce964bda",
   "metadata": {},
   "source": [
    "# ![](https://i.ibb.co/7SXwvBJ/9.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccf687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01ab7ad",
   "metadata": {},
   "source": [
    "## 1. Initialize Parameters and Layer Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe948fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_and_layer_sizes_NN(x_train, y_train):\n",
    "   \n",
    "    parameters = {\"weight1\": np.random.randn(3,x_train.shape[0]) * 0.1,\n",
    "                 \"bias1\": np.zeros((3,1)),\n",
    "                 \"weight2\": np.random.randn(y_train.shape[0],3) * 0.1,\n",
    "                 \"bias2\": np.zeros((y_train.shape[0], 1))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4accc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.shape[0] = 4096 = 64 piksel x 64 piksel\n",
    "# 3 node "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9aeeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(2,3)\n",
    "# mean = 0\n",
    "# variance = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11179d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.zeros(3,1)\n",
    "# output: TypeError: Cannot interpret '1' as a data type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c40a86b",
   "metadata": {},
   "source": [
    "## 2. Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_NN(x_train, parameters):\n",
    "    \n",
    "    Z1 = np.dot(parameters[\"weight\"], x_train) + parameters[\"bias1\"]\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(parameters[\"weight2\"],A1) + parameters[\"bias2\"]\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache\n",
    "\n",
    "# parameters: weight1, bais1, weight2, bias2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc04e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n",
    "# source: NumPy documendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212946d3",
   "metadata": {},
   "source": [
    "## 3. Loss Function and Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683cce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cost\n",
    "\n",
    "def compute_cost_NN(A2, Y, parameters):\n",
    "    \n",
    "    logprobs = np.multiply(np.log(A2),Y)\n",
    "    cost = -np.sum(logprobs) / Y.shape[1]\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98f237f",
   "metadata": {},
   "source": [
    "## 4. Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a65845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation_NN(parameters, cache, X, Y):\n",
    "    \n",
    "    dZ2 = cache[\"A2\"] - Y\n",
    "    dW2 = np.dot(dZ2, cache[\"A1\"].T) / X.shape[1]\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims = True) / X.shape[1]\n",
    "    dZ1 = np.dot(parameters[\"weight2\"].T, dZ2) * (1-np.power(cache[\"A1\"],2))\n",
    "    dW1 = np.dot(dZ1, X.T) / X.shape[1]\n",
    "    db1 = np.sum(dZ1, axis=1, leepdims = True) / X.shape[1]\n",
    "    grads = {\"dweight1\": dW1,\n",
    "             \"dbias1\": db1,\n",
    "             \"dweight2\": dW2,\n",
    "             \"dbias2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd9d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keepdims = keeping array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391eb7a",
   "metadata": {},
   "source": [
    "## 5. Update Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb127c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters_NN(parameters, grads, learning_rate=0.01):\n",
    "    \n",
    "    parameters = {\"weight1\": parameters[\"weight1\"] - learning_rate*grads[\"dweight1\"],\n",
    "                 \"bias1\": parameters[\"bias1\"] - learning_rate*grads[\"bias1\"],\n",
    "                 \"weight2\": parameters[\"weight2\"] - learning_rate*grads[\"weight2\"],\n",
    "                 \"bias2\": parameters[\"bias2\"] - learning_rate*grads[\"bias2\"],}\n",
    "    \n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fed8cf6",
   "metadata": {},
   "source": [
    "## 6. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abf40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_NN(parameters,x_test):\n",
    "    \n",
    "    \n",
    "    A2, cache = forward_propagation_NN(x_test,parameters)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "    \n",
    "    for i in range(A2.shape[1]):\n",
    "        if A2[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e642c83",
   "metadata": {},
   "source": [
    "## 7. Create ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations):\n",
    "    \n",
    "    cost_list = []\n",
    "    index_list = []\n",
    "    \n",
    "    #initialize parameters and layer sizes\n",
    "    parameters = initialize_parameters_and_layer_sizes_NN(x_train, y_train)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "         # forward propagation\n",
    "        A2, cache = forward_propagation_NN(x_train,parameters)\n",
    "        \n",
    "        # compute cost\n",
    "        cost = compute_cost_NN(A2, y_train, parameters)\n",
    "        \n",
    "         # backward propagation\n",
    "        grads = backward_propagation_NN(parameters, cache, x_train, y_train)\n",
    "        \n",
    "         # update parameters\n",
    "        parameters = update_parameters_NN(parameters, grads)\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            cost_list.append(cost)\n",
    "            index_list.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            \n",
    "    plt.plot(index_list,cost_list)\n",
    "    plt.xticks(index_list,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    \n",
    "    # predict\n",
    "    y_prediction_test = predict_NN(parameters,x_test)\n",
    "    y_prediction_train = predict_NN(parameters,x_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))\n",
    "    return parameters\n",
    "\n",
    "    parameters = two_layer_neural_network(x_train, y_train,x_test,y_test, num_iterations=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c6be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(\"photo.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
